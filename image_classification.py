# -*- coding: utf-8 -*-
"""image classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LnTP7d7i4HWjOf_85_CnRolKtSADHC1_
"""

from google.colab import drive
drive.mount('/content/drive')

!nvidia-smi

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
import cv2
import os

img = image.load_img('/content/drive/MyDrive/Colab Notebooks/Training/HAPPY/celebration-navratri-deity.jpg')

img

i1 = cv2.imread('/content/drive/MyDrive/Colab Notebooks/Training/HAPPY/celebration-navratri-deity.jpg')

i1

i1.shape

train = ImageDataGenerator(rescale = 1/200)
validation = ImageDataGenerator(rescale = 1/200)

train_dataset = train.flow_from_directory(r'/content/drive/MyDrive/Colab Notebooks/Training',
                                         target_size = (200,200),
                                         batch_size = 3,
                                         class_mode = 'binary')
validation_dataset = validation.flow_from_directory('/content/drive/MyDrive/Colab Notebooks/Validation',
                                                    target_size=(200,200),
                                                    batch_size=32,
                                                    class_mode='binary')

train_dataset.class_indices

train_dataset.classes

# now we are applying maxpooling

model = tf.keras.models.Sequential([ tf.keras.layers.Conv2D(16,(3,3),activation = 'relu',input_shape = (200,200,3)),
                                    tf.keras.layers.MaxPool2D(2,2), #3 filtr we applied hear
                                    #
                                    tf.keras.layers.Conv2D(32,(3,3),activation = 'relu'),
                                    tf.keras.layers.MaxPool2D(2,2),
                                    #
                                    tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),
                                    tf.keras.layers.MaxPool2D(2,2),
                                    ##
                                    tf.keras.layers.Flatten(),
                                    ##
                                    tf.keras.layers.Dense(512, activation = 'relu'),
                                    #
                                    tf.keras.layers.Dense(1,activation= 'sigmoid')
                                    ]
                                    )

model.compile(loss='binary_crossentropy',
              optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),
              metrics=['accuracy'])

model_fit=model.fit(train_dataset,epochs=10)

dir_path='/content/drive/MyDrive/Colab Notebooks/Testing'
for i in os.listdir(dir_path):
  print(i)

dir_path='/content/drive/MyDrive/Colab Notebooks/Testing'
for i in os.listdir(dir_path):
  img=image.load_img(dir_path+'//'+i,target_size=(200,200))
  plt.imshow(img)
  plt.show()

dir_path='/content/drive/MyDrive/Colab Notebooks/Testing'
for i in os.listdir(dir_path):
  img=image.load_img(dir_path+'//'+i,target_size=(200,200))
  plt.imshow(img)
  plt.show()

  x=image.img_to_array(img)
  x=np.expand_dims(x,axis=0)
  images=np.vstack([x])

  val=model.predict(images)
  if val==0:
    print("happy")
  else:
    print("sad")



"""frontend creation using gradio and python"""

import gradio as gr
from PIL import Image
import numpy as np

def predict_mood(image):
    # Resize the image to (200, 200) as expected by the model
    img = image.resize((200, 200))
    # Convert the image to a numpy array
    x = np.array(img)
    # Expand dimensions to create a batch of 1 image
    x = np.expand_dims(x, axis=0)
    # Normalize the image (if the model was trained with normalized inputs)
    # The model was trained with rescale=1/200, so we should apply the same scaling here.
    x = x / 200.0
    # Make prediction
    val = model.predict(x)[0][0]
    # Interpret the prediction
    if val < 0.5:
        return 'Happy'
    else:
        return 'Not Happy'

iface = gr.Interface(fn=predict_mood,
                     inputs=gr.Image(type='pil',label='upload a image'),
                     outputs=gr.Text(label='Predicted Mood'),
                     title='Mood Classification',
                     description='Upload an image and get the predicted mood.')
iface.launch()

